{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b429b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 69 chunks\n"
     ]
    }
   ],
   "source": [
    "# 04-clip-index.ipynb\n",
    "# Cell 1 - install (if needed)\n",
    "# import importlib, sys, subprocess\n",
    "# pkgs = [\"sentence-transformers\", \"faiss-cpu\", \"tqdm\", \"numpy\"]\n",
    "# missing = [p for p in pkgs if importlib.util.find_spec(p) is None]\n",
    "# if missing:\n",
    "#     subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + missing)\n",
    "\n",
    "# Cell 2 - paths & load chunks\n",
    "from pathlib import Path\n",
    "import json\n",
    "ROOT = Path.cwd().parent\n",
    "CHUNKS_FILE = ROOT / \"data\" / \"processed\" / \"chunks.jsonl\"\n",
    "OUT_DIR = ROOT / \"embeddings\"   # we will store clip_text_embeddings.npy and clip_faiss_index.bin here\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chunks = []\n",
    "with open(CHUNKS_FILE, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            chunks.append(json.loads(line))\n",
    "print(\"Loaded\", len(chunks), \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b839a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaydobariya/Library/Python/3.14/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - load CLIP text encoder via sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# choose a CLIP-like text model (sentence-transformers has CLIP text encoders)\n",
    "# examples: 'openai/clip-vit-base-patch32' isn't directly in s-t; use \"clip-ViT-B-32\" from sentence-transformers hub\n",
    "CLIP_TEXT_MODEL = \"clip-ViT-B-32\"   # small, fast; swap for better model if needed\n",
    "clip_model = SentenceTransformer(CLIP_TEXT_MODEL)\n",
    "texts = [c[\"text\"] for c in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe496249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (69, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - compute text embeddings (CLIP text embeddings)\n",
    "batch_size = 32\n",
    "embs = clip_model.encode(texts, show_progress_bar=True, batch_size=batch_size, convert_to_numpy=True)\n",
    "print(\"Embeddings shape:\", embs.shape)\n",
    "\n",
    "# normalize (cosine similarity if desired)\n",
    "# It is common to L2-normalize CLIP vectors for cosine similarity\n",
    "def normalize_rows(x):\n",
    "    norms = np.linalg.norm(x, axis=1, keepdims=True) + 1e-12\n",
    "    return x / norms\n",
    "\n",
    "embs_norm = normalize_rows(embs.astype(\"float32\"))\n",
    "\n",
    "# Save embeddings\n",
    "np.save(OUT_DIR / \"clip_text_embeddings.npy\", embs_norm)\n",
    "with open(OUT_DIR / \"clip_text_chunks_meta.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump([{\"id\": c[\"id\"], \"title\": c[\"title\"], \"word_count\": c[\"word_count\"]} for c in chunks], f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a7cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CLIP FAISS index with 69 vectors at /Users/jaydobariya/Desktop/RAG Project/embeddings/clip_faiss_index.bin\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - build FAISS index (IndexFlatIP for cosine with normalized vectors)\n",
    "import faiss\n",
    "d = embs_norm.shape[1]\n",
    "index = faiss.IndexFlatIP(d)   # inner product on normalized vectors = cosine similarity\n",
    "index.add(embs_norm.astype(\"float32\"))\n",
    "faiss.write_index(index, str(OUT_DIR / \"clip_faiss_index.bin\"))\n",
    "print(\"Saved CLIP FAISS index with\", index.ntotal, \"vectors at\", OUT_DIR / \"clip_faiss_index.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68d8899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top indices: [62 35 33 53 48]\n",
      "62 Taj Mahal__27 Taj Mahal According to Ebba Koch, art historian and international expert in the understanding and interpretation of Mughal architecture and the Taj Mahal, the planning of the entire compound symbolises earthly \n",
      "35 Taj Mahal__0 Taj Mahal The Taj Mahal ( TAHJ mə-HAHL, TAHZH -⁠; Hindustani: [taːdʒ ˈmɛɦ(ɛ)l]; lit. 'Crown of the Palace') is an ivory-white marble mausoleum on the right bank of the river Yamuna in Agra, Uttar Pradesh, India\n",
      "33 Red Fort__19 Red Fort West of the hammam is the Moti Masjid, the Pearl Mosque. A later addition to the Red Fort, the mosque was built in 1659 as a private place of worship for Emperor Aurangzeb. This small, three-domed str\n",
      "53 Taj Mahal__18 Taj Mahal The Taj Mahal complex is enclosed by crenellated red sandstone walls on three sides, with the side facing the Yamuna river left open. Outside the complex walls, there are other mausoleums dedicated to\n",
      "48 Taj Mahal__13 Taj Mahal Situated within the screen in the upper main chamber are the likenesses of the tombs of Mumtaz Mahal and Shah Jahan with the actual burials done below in the lower tomb chamber. From the southern main\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 - sanity test: nearest neighbors for a caption sample\n",
    "sample_caption = \"white marble mausoleum in Agra\"\n",
    "q = clip_model.encode([sample_caption], convert_to_numpy=True)\n",
    "q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)\n",
    "D, I = index.search(q.astype(\"float32\"), 5)\n",
    "print(\"Top indices:\", I[0])\n",
    "for idx in I[0]:\n",
    "    print(idx, chunks[idx][\"id\"], chunks[idx][\"title\"], chunks[idx][\"text\"][:200].replace(\"\\n\",\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
